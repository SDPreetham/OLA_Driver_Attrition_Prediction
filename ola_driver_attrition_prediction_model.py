# -*- coding: utf-8 -*-
"""OLA-Driver_Attrition_Prediction_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1udD0559ZVVRehX-9WKO8Pvx6wmYf3je8

## **Ola Attrition Analytics: Modelling Driver Turnover Risk**

- By S D Preetham

**Problem Description:**

* Ola faces a growing challenge in retaining its driver base amid high attrition and competition from Uber. From a business perspective, retaining drivers is significantly more cost-effective than acquiring new ones. Moreover, many new recruits are people who don’t even own cars, further adding to onboarding complexity and expense.

* Ultimately, the objective here is to develop a predictive model that uses driver demographic, performance and tenure data to identify drivers at high risk of leaving. By leaveraging these insights, Ola can take proactive retention measures, optimize resource allocation and strengthen workforce stability thereby ensuring better customer satisfaction and business sustainability.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('ola.csv')
df.head()

"""### **Exploratory Data Analysis:**"""

print('The number of datapoints: ', df.shape[0])
print('The number of features: ', df.shape[1])

df.dtypes

df.info()

missing = df.isnull().sum()
missing[missing > 0].sort_values(ascending=False)

duplicates = df.duplicated().sum()
duplicates

"""**Insights:**

* It is observed that there are no duplicate values in the dataset.
However, there are null values present across various columns in the dataset.
* The column 'LastWorkingDate' has the highest number of null values. Other columns with null values include 'Age' and 'Gender'.
"""

df['MMM-YY'] = pd.to_datetime(df['MMM-YY'], format='%b-%y',errors='coerce')
df['Dateofjoining'] = pd.to_datetime(df['Dateofjoining'], format='%d/%m/%y')
df['LastWorkingDate'] = pd.to_datetime(df['LastWorkingDate'], format='%d/%m/%y')

"""### **Visual Analysis:**

**Univariate Analysis:**
"""

continuous = ['Age', 'Income', 'Total Business Value', 'Quarterly Rating']

plt.figure(figsize=(14,10))

for i, col in enumerate(continuous):
  plt.subplot(2,2,i+1)
  sns.histplot(df[col], kde = True, bins = 30, color='orange')
  plt.title(f'Distribution of {col}')
  plt.xlabel(col)
  plt.ylabel('Count')

plt.show()

"""**Insights:**

* From the age countplot, it is evident that most of the drivers are aged between 30-37.
* It is evident from income distribution that most of the drivers are paid a salary ranging between 30000-70000.
* The business value brought by drivers is minimal.
*  Many drivers receive low performance ratings, which could lead to attrition.
"""

categorical = ['Gender','Education_Level','Grade','Joining Designation']

plt.figure(figsize=(14,10))

for i,col in enumerate(categorical):
  plt.subplot(2,2,i+1)
  sns.countplot(data=df, x=col, color='darkblue', order=df[col].value_counts().index)
  plt.title(f'Distribution of {col}')
  plt.xlabel(col)
  plt.ylabel('Count')

plt.show()

"""**Insights:**
* Out of the 19104 drivers, over 10000 drivers are male, indicating a high number of male drivers at Ola.
* Ola's driver base consists of a mix of drivers with different education levels.
* The grade of a majority of drivers ranges between 1-3 indicating that the workforce is primarily made up of entry to mid-level drivers. Promotions or grade growth could be a lever for retention or motivation.
* The joining designation also mostly ranges between 1-3.

**Bivariate Analysis:**

* Analyzing attrition rates across each continuous variable:
"""

df['Attrition'] = df['LastWorkingDate'].notna().astype(int)

plt.figure(figsize=(14,10))

for i, col in enumerate(continuous):
  plt.subplot(2,2,i+1)
  sns.boxplot(data=df, x= 'Attrition', y= col, color = 'darkgreen')
  plt.title(f'{col} vs Attrition')
  plt.xlabel('Attrition')
  plt.ylabel(col)


plt.show()

"""**Insights:**

* From the income distribution, it is evident that the attrited drivers had a lower median income(~50,000) than the retained drivers (nearly 65,000), indicating low incomes lead to driver attrition.

* The retained drivers contributed to a large range of income.

* The median quarterly rating of retained drivers is higher than that of attrited drivers.This indicates an inverse relationship between performance rating and attrition.

* **Analyzing attrition rates across each categorical variable:**
"""

plt.figure(figsize=(14,10))

for i, col in enumerate(categorical):
  plt.subplot(2,2,i+1)
  sns.boxplot(data=df, x='Attrition', y = col, color='pink')
  plt.title(f'{col} vs Attrition')
  plt.xlabel('Attrition')
  plt.ylabel(col)

plt.show()

"""**Insights:**

* Across the categorical features, no significant difference is observed between attrited and retained drivers.

**Correlation Heatmap:**
"""

num_df = df.select_dtypes(include='number')

corr_matrix = num_df.corr()

plt.figure(figsize=(10,8))
sns.heatmap(corr_matrix, annot=True, cmap='Blues', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

"""**Insights:**
* There is a negative correlation between Quarterly Rating and Attrition	(-0.26). This indicates	drivers with low ratings are more likely to leave.

* Income, while moderately correlated, still shows a trend that low pay increases attrition.

* Demographics such as gender, education are not predictive of attrition in this case.
"""

top_cities = df['City'].value_counts().nlargest(10).index
plt.figure(figsize=(6, 4))
sns.countplot(data=df[df['City'].isin(top_cities)], x='City', hue='Attrition', order=top_cities)
plt.title("Attrition by Top 10 Cities")
plt.xlabel('City')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### **Data Preprocessing:**"""

# Quarterly Rating Increase
df = df.sort_values(['Driver_ID', 'MMM-YY'])
df['prev_rating'] = df.groupby('Driver_ID')['Quarterly Rating'].shift(1)
df['quarterly_rating_increase'] = (df['Quarterly Rating']>df['prev_rating']).astype(int)

# Monthly Income Increase
df['prev_income'] = df.groupby('Driver_ID')['Income'].shift(1)
df['monthly_income_increase'] = (df['Income']>df['prev_income']).astype(int)

# K-NN Imputation
from sklearn.impute import KNNImputer

numeric_columns = df.select_dtypes(include=['int64','float64']).columns
knn_imputer = KNNImputer(n_neighbors=5)
df[numeric_columns] = knn_imputer.fit_transform(df[numeric_columns])

from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

# Step 1: Drop datetime columns
datetime_cols = df.select_dtypes(include=['datetime64[ns]', 'datetime64']).columns
df = df.drop(columns=datetime_cols)

X = df.drop('Attrition', axis=1)
y = df['Attrition']

# Encode categorical columns before splitting
le = LabelEncoder()
X['Gender'] = le.fit_transform(X['Gender'])

# One-hot encode 'City'
X = pd.get_dummies(X, columns=['City'], drop_first=True)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

X_test = X_test.reindex(columns=X_train.columns, fill_value=0)

# SMOTE on training set
smote = SMOTE(random_state=42)
X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

# Scaling the data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_res)
X_test_scaled = scaler.transform(X_test)

"""**Explanation:**
* Label Encoding: The Gender column is converted from text values (like 'Male', 'Female') to numerical labels (0 or 1) using LabelEncoder.
* One-Hot Encoding: The City column is converted into multiple columns (one for each city) with binary values (0 or 1) indicating the driver's city. This is called one-hot encoding and is used to represent categorical data without implying any order.

* SMOTE: Since there might be more drivers who stayed than those who left, SMOTE is used to generate synthetic samples for the minority class (attrition cases) to balance the dataset and improve model performance.

* StandardScaler: It is applied to scale the numerical features so they have zero mean and unit variance. This can help improve the performance of some machine learning algorithms that are sensitive to feature scaling.

### **Model Training:**
"""

from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc

"""**Random Forest:**"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint
rf = RandomForestClassifier(random_state=42, class_weight='balanced')

rf_param_grid = {
    'n_estimators': [100, 150],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt']
}

rf_random = RandomizedSearchCV(
    estimator=rf,
    param_distributions=rf_param_grid,
    n_iter=10,
    scoring='roc_auc',
    n_jobs=-1,
    cv=3,
    verbose=1,
    random_state=42
)

rf_random.fit(X_train_scaled, y_train_res)
best_rf = rf_random.best_estimator_

"""**Steps Explained:**
1. Create Base Model: A Random Forest model is created with initial settings (random_state and class_weight).

2. Define Hyperparameter Grid: A range of values for important model settings (hyperparameters) is specified in a dictionary.

3. Set Up Hyperparameter Search: RandomizedSearchCV is configured to find the best hyperparameter combination using the defined grid, performance metric (ROC AUC), cross-validation and other settings.

4. Perform Search and Select Best Model: The search is executed on the training data and the best-performing model (with optimal hyperparameters) is stored.

**XGBoost:**
"""

from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV

xgb = XGBClassifier(
    objective='binary:logistic',
    eval_metric='auc',
    use_label_encoder=False,
    random_state=42
)

param_grid = {
    'n_estimators': [100, 150, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.05, 0.1, 0.2],
    'subsample': [0.7, 0.8],
    'colsample_bytree': [0.7, 0.8],
    'scale_pos_weight': [3, 5, 10]  # adjust based on imbalance ratio
}

xgb_random = RandomizedSearchCV(
    estimator=xgb,
    param_distributions=param_grid,
    n_iter=10,
    scoring='roc_auc',
    n_jobs=-1,
    cv=3,
    verbose=1,
    random_state=42
)

xgb_random.fit(X_train_scaled, y_train_res)

best_xgb = xgb_random.best_estimator_

"""**Steps Explained:**

1. Create an XGBoost classifier: An XGBClassifier object is initialized with specific settings for binary classification and performance evaluation using AUC (Area Under the Curve).


2. Define hyperparameter grid: A dictionary param_grid is created, containing a range of values for various XGBoost hyperparameters. These hyperparameters control the model's complexity and learning process.

3. Set up RandomizedSearchCV: RandomizedSearchCV is configured to find the best combination of hyperparameters from the param_grid. It samples thehyperparameter combinations randomly and evaluates them using cross-validation (cv=3) Subsequently, the combination that maximizes the ROC AUC score is selected.

4. Train and select the best model: The fit method is called on xgb_random to train the model with different hyperparameter combinations on the training data (X_train_scaled, y_train_res). The best-performing model is stored in the best_xgb variable.

**Evaluation Function:**
"""

def evaluate_model(name, y_test, y_pred, y_prob):
  print(f"\n--- {name} Evaluation ---")
  print('Classification Report: ')
  print(classification_report(y_test, y_pred))
  print('Confusion Matrix: ')
  print(confusion_matrix(y_test, y_pred))
  print(f"ROC AUC Score: {roc_auc_score(y_test, y_prob):.4f}")

y_pred_rf = best_rf.predict(X_test_scaled)
y_prob_rf = best_rf.predict_proba(X_test_scaled)[:,1]

y_pred_xgb = best_xgb.predict(X_test_scaled)
y_prob_xgb = best_xgb.predict_proba(X_test_scaled)[:,1]

evaluate_model("Random Forest (Tuned)", y_test, y_pred_rf, y_prob_rf)
evaluate_model("XGBoost (Tuned)", y_test, y_pred_xgb, y_prob_xgb)

"""**Explanation:**
* This code segment uses the best performing Random Forest and XGBoost models to predict driver attrition (both as a binary outcome and probability) on unseen test data. It then evaluates the performance of both models using the evaluate_model function, which calculates and displays key metrics like classification report, confusion matrix and ROC AUC score, enabling a comprehensive performance comparison.

**ROC-AUC Curve:**
"""

fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)
fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)

plt.figure(figsize=(10, 6))
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc(fpr_rf, tpr_rf):.4f})')
plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {auc(fpr_xgb, tpr_xgb):.4f})')
plt.plot([0, 1], [0, 1], 'k--', label='No Skill')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC AUC Curve')
plt.legend()
plt.grid(True)
plt.show()

"""**Insights:**
* Random Forest:
 *  A high overall accuracy of 88% is obtained which is driven by strong performance on majority class (non-attrition).

 * However, a poor recall for attrition class (12%) indicates that the model fails to detect most drivers who are likely to leave.

 * Low precision (17%) on attrition means many false alarms.

 * Despite high accuracy, the model’s AUC of 0.8056 suggests limited ability to distinguish attrition cases from non-attrition.

* XGBoost:
 * Although the accuracy obtained is 82% the model offers balanced performance across classes as there is better minority class detection.

 * A moderate recall of 48% is obtained for attrition, catching nearly half of the leavers.

 * However, the precision is low (22%), implying the possible presence of false positives.

 * An AUC of 0.8057 indicates solid predictive capability and better class separation than the previous model.

**Maximizing attrition recall efficiency by using Stratified K-Fold XGBoost:**
"""

from sklearn.model_selection import GridSearchCV, StratifiedKFold

xgb = XGBClassifier(
    objective='binary:logistic',
    scale_pos_weight=(len(y_train_res) - sum(y_train_res)) / sum(y_train_res),
    use_label_encoder=False,
    eval_metric='logloss',
    random_state=42,
    n_jobs=-1
)
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0],
    'gamma': [0, 1, 5]
}
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
grid_search = GridSearchCV(
    estimator=xgb,
    param_grid=param_grid,
    scoring='recall',  # Focus on recall for class 1
    cv=cv,
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train_scaled, y_train_res)
best_xgb = grid_search.best_estimator_

y_prob = best_xgb.predict_proba(X_test_scaled)[:, 1]
precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)

# Plot precision-recall vs threshold
plt.figure(figsize=(8, 5))
plt.plot(thresholds, precisions[:-1], label='Precision')
plt.plot(thresholds, recalls[:-1], label='Recall')
plt.xlabel('Threshold')
plt.ylabel('Score')
plt.title('Precision-Recall vs Threshold')
plt.legend()
plt.grid()
plt.show()

# Select a threshold that balances both (example: recall ≥ 0.3, precision ≥ 0.2)
threshold = 0.3
y_pred_adjusted = (y_prob >= threshold).astype(int)

print("\n--- Final XGBoost Evaluation ---")
print("Classification Report:\n", classification_report(y_test, y_pred_adjusted))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_adjusted))
print("ROC AUC Score:", roc_auc_score(y_test, y_prob))

"""**Insights:**

* The model now achieves very high recall (0.86) for the attrition class, meaning it correctly identifies most drivers who are likely to leave.

* However, precision (0.20) is low, indicating many non-attrition drivers are falsely predicted as leaving.

* Overall accuracy dropped to 70%, but this trade-off is acceptable here, as identifying potential attrition is the top priority.

* An ROC-AUC score of 0.837 suggests strong overall class separation, despite the class imbalance.

### **Actionable Insights and Recommendations:**

* **Brief Explanation of Performance Metrics in Classification Report:**

 * ROC-AUC Score: The ROC AUC score measures the model's ability to distinguish between classes (drivers leaving vs. staying). A higher AUC score indicates better discriminatory power, meaning the model is better at correctly ranking drivers in terms of their risk of attrition.

 *  Precision: "Of all the drivers we predicted as attrition, how many truly left?"

   * Precision= True Positives/(True Positives + False Positives)
   * High precision indicates few false positives, indicating, no wrong classification of non-attrition drivers when attrition happens.
 * Recall: "Of all the drivers who actually left, how many did we correctly predict?"
   * Recall= True Positives/(False Negatives+True Positives)
   * High recall means few false negatives, suggesting drivers who are actually going to leave were rightly identified.

 * F1-Score: The harmonic mean of precision and recall, providing a balance between the two.
   * A balanced F1-score indicates that the model strikes a good balance between precision and recall.

The model is effective at identifying most drivers who are at risk of leaving, even if it also misclassifies some loyal drivers.
This recall-focused model can serve as an early warning system to flag potentially at-risk drivers.

* Factors contributing heavily to predictions likely include:

  * Low monthly income
  * Reduced business acquisition
  * Lower quarterly ratings or driver grades
  * Short tenure


* **Recommendations to minimize Attrition:**

  * **Income Assurance Programs**:
   Consider increasing incomes  for drivers in lower-income brackets or those showing declining income trends.
  * **Personalized Engagement**:
Gather qualitative feedback from drivers flagged as high-risk. This would address any possible concerns they may have.
  * **Training & Upskilling**:
Provide training opportunities for drivers with poor ratings or low business acquisition.
  * **Attrition Dashboard**:
Deploy the model in production to continuously monitor at-risk drivers.
  * **Accident Insurance and Competitor Analysis**:
Provide accident insurance and safety training, particularly for long-tenured drivers to ensure their overall well-being. Regularly compare Ola’s driver benefits, support structures and earnings with competitors (like Uber or Rapido) and adjust policies accordingly.
 * **Driver Exit Interviews and Feedback Loop**:
Collect and analyze feedback from attrited drivers. Ensure to feed it into the model for refinement and operational changes.

By integrating this predictive model with Ola's driver management system, the company can minimize churn, improve operational stability,
while enhancing driver satisfaction and optimizing incentive costs.
"""